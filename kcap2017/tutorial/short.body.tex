\section{A music data model}\label{sec:model}
The DOREMUS model\footnote{\url{http://data.doremus.org/ontology/}} is an extension of FRBRoo for describing cultural objects~\cite{doerr2008frbroo}, applied to the specific domain of music. This is a dynamic model centered on a Work-Expression-Event triplet, which can describe different parts of the life of a work, like the Performance, the Publication or the creation of a derivative Work, each one incorporating the expression from which it comes from. DOREMUS adds specific classes and properties to FRBRoo, such as the musical key, the genre, the tempo, the medium of performance (MoP), etc.~\cite{choffe2016doremus}.

Each triplet contains an information that, at the same time, can live autonomously and be linked to the other entities. Thinking about a classic work, we will have a triplet for the composition, one for each performance event, one for every manifestation (i.e. the score), etc., all connected in the graph.

A large number of properties that are involved in the music description are supposed to contain values that are shared among different entities. These literal values can be expressed in multiple languages or in alternative forms (e.g. ``sax'' and ``saxophone''), making reconciliation hard. Our choice is to use controlled vocabularies for those common concepts. We are using SKOS as representation model, that allows to specify for each concept the preferred and the alternative labels in multiple language, to define a hierarchy between the concepts, and to add comments and notes for describing the entity and help the annotation activity. Each concept becomes a common node in the musical graph that can connect a musical work to another, an author to a performer, etc. We collected, implemented and published 15 controlled vocabularies belonging to 6 different categories. Some of them are already available on the web, but some others were not (or not completely) published in a suitable format for the Web of Data, and some others did not exist at all so we generated them on the base of real data coming from the partners, enriched by an editorial process that involved also librarians\footnote{\url{https://github.com/DOREMUS-ANR/knowledge-base/tree/master/vocabularies}}.

\section{Data Conversion}\label{sec:convert}
For representing music metadata, libraries make commonly use of the MARC format, which consists in a succession of fields and subfields separated by tags. Although MARC is a standard, its adoption is restricted to the library world. The benefits of moving from MARC to an RDF-based solution consist in the interoperability and the integration among libraries and with third party actors, with the possibility of realizing smart federated search~\cite{byrne2010strongest, alemu2012linked}.

\subsection{From MARC to RDF}
We develop and release \smallsc{marc2rdf}, an open source prototype for the automatic conversion of MARC bibliographic records to RDF using the DOREMUS ontology~\cite{lisena2016exploring}. The process relies on explicit expert-defined transfer rules that indicate where in the MARC file to look for what kind of information, as well as useful examples. The converter is composed of different modules, that works in succession. A \textit{file} parser reads the MARC file and makes the content accessible by field and subfield number. Then, it builds the RDF graph reading the fields and assigning their content to the DOREMUS property suggested in the transfer rules. The \textit{free-text interpreter} extracts further information from the plain text fields, that includes editorial notes. The parsing is realized through empirically defined regular expression, that are going to be supported by Named Entity Recognition techniques as a future work. Finally, the \textit{string2vocabulary} component performs an automatic mapping of string literals to URIs coming from controlled vocabularies. As additional feature, this component is able to recognise and correct some noise that is present in the source MARC file: as an example, this is the case of musical keys declared as genre and vice-versa.

\subsection{Dealing With Heterogeneous Formats}
Apart from MARC, we are converting other source bases (in XML), that are too specific to be handled by a single converter. Therefore, we developed \textit{ad hoc} software that have a generic workflow: parse the input file and collect the required information, create the graph structure in RDF, run the \textit{string2vocabulary} module described previously. This procedure creates different graphs, one for each source. Those source databases are complementary but also contain overlaps (e.g. two databases that describe the same work or the same performance with complementary metadata). We have started to automatically interlink the datasets, so that the resulting knowledge graph provides a richer description of each work.

\subsection{Answering Complex Queries}
Before the beginning of the project, a list of questions have been collected from experts of the partner institutions\footnote{\url{https://github.com/DOREMUS-ANR/knowledge-base/tree/master/query-examples}}. These questions reflect real needs of the institutions and reveal problems that they face daily in the task of selecting information from the database (e.g. concert organisation, broadcast programming) or for supporting librarian and musicologist studies. They can be related to practical use cases (the search of all the scores that suit a particular formation), to musicologist topics (the music of a certain region in a particular period), to interesting stats (the works usually performed or published together), or to curious connections between works, performances or artists. Most of the questions are very specific and complex, so that it is very hard to find their answer by simply querying the search engines currently available.

\section{Exploration and Recommendation}\label{sec:explore}
We developed the first version of \textsc{Overture}, a web prototype of an exploratory search engine for DOREMUS data. The application makes requests directly to our SPARQL endpoint\footnote{\url{http://data.doremus.org/sparql}} and provides the information in a nice user interface. The application goal is to show a way to visualise the knowledge in DOREMUS and host a recommender system.

\subsection{Visualizing the Complexity}
At the top of the user interface, the navigation bar allows the user to navigate between the main concepts of the DOREMUS model. The challenge is in giving to the final user a complete vision on the data of each class and letting him/her understand how they are connected to each other.
We keep as example Beethoven's \textit{Sonata for piano and cello n.1} \footnote{\url{http://overture.doremus.org/expression/614925f2-1da7-39c1-8fb7-4866b1d39fc7}}. Aside from the different versions of the title, the composer and a textual description, the page provides details on the information we have about the work. When these values come from a controlled vocabulary, a link is present in order to search for expressions that share the same value. A timeline shows the most important events in the story of the work (the composition, the premiere, the first publication). Other performances and publications can be represented below. The portrait of the composer in background comes from DBpedia. It is retrieved thanks to the presence in the DOREMUS database of \texttt{owl:sameAs} links. These links comes in part from the International Standard Name Identifier (ISNI) service, in part thanks to an interlinking realised by matching the artist name, birth and death date in the different datasets.

\subsection{Music Recommendation}
What we should suggest to an user listening Beethoven? Similar musicians should share with the German composer some features: period, genre, key, casting or similar instrument played. How to define a similarity measure that involves this concepts?

We propose a solution based on graph embeddings generated at different levels:
(i) For simple features (genre, key, mop), we compute for each term an embedding applying \textit{node2vec}~\cite{node2vec-kdd2016} on two sub-graphs: the one of the controlled vocabularies and the one corresponding to the usage of their values in the DOREMUS dataset;
(ii) For complex features (artist), we generate the embeddings by the combination of its corresponding feature embedding;
(iii) Finally, we combine simple and complex feature embeddings, following the same rules, to obtain the embedding of a work.

The use of embeddings reduces the similarity problem as the reverse of an euclidean distance. If some properties are missing, we apply a penalisation computed as percentage of missing feature in the target vector with respect to the seed one~\cite{lisena2017combining}.

The biggest advantage of this method is that the embeddings computation is required only for the simple features, then each embedding is re-used in different combination. Moreover, different weights can be assigned to each property in order to tune up the recommendation. As future work, we plan to experiment with neural networks in order to discover the best strategy to weight the contribution of each dimension in the similarity score. 

\paragraph{\textbf{ACKNOWLEDGMENTS}} This work has been partially supported by the French National Research Agency (ANR) within the DOREMUS Project, under grant number ANR-14-CE24-0020.
